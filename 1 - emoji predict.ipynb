{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojitranslate project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part one - learning to predict emojis from tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adapted from the Osinga deep learning cookbook - using the Twitter API to sample EN language tweets that contain exactly one emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nickdbn/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import twitter\n",
    "import emoji\n",
    "# import itertools\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential, optimizers, regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils import to_categorical\n",
    "import keras.callbacks\n",
    "from keras.backend import clear_session\n",
    "#import json\n",
    "\n",
    "import os\n",
    "# import nb_utils\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, Embedding, GlobalMaxPooling1D#, Merge \n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate, Average\n",
    "\n",
    "# from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "😂        44794\n",
       "😭        18356\n",
       "❤        14875\n",
       "emoji    10434\n",
       "😍        10025\n",
       "🔥         9518\n",
       "🤣         6295\n",
       "🤔         4874\n",
       "🙏         4839\n",
       "😩         4675\n",
       "💕         4612\n",
       "😊         4363\n",
       "🖤         4313\n",
       "👀         3908\n",
       "✨         3789\n",
       "💜         3744\n",
       "👏         3639\n",
       "🙄         3474\n",
       "💀         3296\n",
       "🎉         3192\n",
       "🙌         3004\n",
       "😘         2876\n",
       "😏         2865\n",
       "💯         2744\n",
       "💙         2665\n",
       "😔         2616\n",
       "👍         2576\n",
       "😎         2425\n",
       "😉         2408\n",
       "♥         2386\n",
       "         ...  \n",
       "🏨            1\n",
       "🈲            1\n",
       "⏸            1\n",
       "◀            1\n",
       "🏣            1\n",
       "📏            1\n",
       "🛤            1\n",
       "🚾            1\n",
       "👝            1\n",
       "🗜            1\n",
       "🧙            1\n",
       "🗄            1\n",
       "👲            1\n",
       "🈳            1\n",
       "🚈            1\n",
       "👷            1\n",
       "🚇            1\n",
       "↕            1\n",
       "⛎            1\n",
       "🧚            1\n",
       "➗            1\n",
       "📪            1\n",
       "🕠            1\n",
       "🧘            1\n",
       "💇            1\n",
       "📤            1\n",
       "📇            1\n",
       "💹            1\n",
       "📗            1\n",
       "🏬            1\n",
       "Name: emoji, Length: 1069, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets = pd.read_csv('data/emojis_homemade.csv')\n",
    "all_tweets['emoji'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360433, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Unnamed: 0                                               text emoji\n",
       "0              0.0  RT @mydear_bangtan: [VID] 181023 - Foi adicion...     ©\n",
       "1              1.0  RT @WuYiFan_KrisBar: 181023 Kris Wu Studio upd...     💫\n",
       "2              2.0  RT @TrendsPrabhas: Now you are watching Indian...     😎\n",
       "3              3.0                                    dats for keeps      💛\n",
       "4              4.0  RT @xruiztru: WHO ARMS THE SAUDIS?\\n\\n  🇺🇸US 5...     🏳\n",
       "5              5.0  RT @xxxfreaknasty2: interracial couple go at i...     🌝\n",
       "6              6.0               @Eric_Deshaun Holy shit no I think.      😩\n",
       "7              7.0     RT @fanmutuals: army, follow who retweet this      👑\n",
       "8              8.0  RT @_Simplykpop: Simply K-Pop harddrive dump\\n...     🤩\n",
       "9              9.0  Happy birthday nellie @thelittlegend, hope you...     ❤\n",
       "10            10.0  RT @montparnasty: \"I have passed through fire\"...     💕\n",
       "11            11.0  RT @Jason_Mckeown: Look how empty Valley Parad...     😟\n",
       "12            12.0  RT @hellohonne: Incredible to be involved in t...     😱\n",
       "13            13.0  RT @btsvotingteam: Too much feels \\n\\n#BTS #MP...     😢\n",
       "14            14.0  RT @premierleague: #PL TOP SCORERS \\n\\n7 - @ha...     🔥\n",
       "15            15.0  [DEPASCAL] RUSSEL HOODIE BLUE\\n https://t.co/C...     🔗\n",
       "16            16.0  The joys of having a make up artist as your be...     😂\n",
       "17            17.0  RT @EXOGlobal: [!] #TEMPO_KAI is currently tre...     🎊\n",
       "18            18.0     RT @fanmutuals: army, follow who retweet this      👑\n",
       "19            19.0       @slicksean Someone didn’t read the article.      🙄\n",
       "20            20.0  RT @mefeater: Happy 23rd Birthday to Duckie Th...     💕\n",
       "21            21.0  RT @followprojecten: follow everyone who retwe...     💓\n",
       "22            22.0  RT @hellohonne: Incredible to be involved in t...     😱\n",
       "23            23.0  RT @abusedmember: ⚀Re-enter the red cube⚀\\n\\n*...     🏁\n",
       "24            24.0  WOW @Just_Ceeks let me know when I can come pl...     🙃\n",
       "25            25.0  RT @MarkLand0802: markno～\\n#NCT #Mark #MarkLee...     🤟\n",
       "26            26.0  RT @SAPTechEd: Don't forget! The #SAPTechEd ne...     🍻\n",
       "27            27.0  RT @YuH8TM3:  \\nYou have all decided to push y...     🤔\n",
       "28            28.0                    Somebody stop simone biles omg      🔥\n",
       "29            29.0              @mrfairyvideo @__jim_in Wth i see...      😨\n",
       "...            ...                                                ...   ...\n",
       "360403         3.0  RT @nubiankemett: People - Check what you Eat ...     😱\n",
       "360404         4.0  RT @hotniqqha: UMEME out here proving somethin...     😂\n",
       "360405         5.0  RT @hyuninmoments: Hello Stays️ This is a new ...     ❣\n",
       "360406         6.0  RT @LAY_zhang_: Thank you so much for all the ...     ❤\n",
       "360407         7.0  did anyone else catch what @GraysonDolan said?...     😂\n",
       "360408         8.0                              @PMU_Sportif Laborde      👌\n",
       "360409         9.0  Yalbbeeehhhh — Fdait ro7chhh https://t.co/pvEt...     😤\n",
       "360410        10.0  RT @WistfulCass: If you're choking on an unrip...     😊\n",
       "360411        11.0     RT @pyewaw: follow the fastest 100 to retweet      😈\n",
       "360412        12.0      @sunainak you’re a friend of Karan Johar’s?!      😂\n",
       "360413        13.0                          just give me 2 hours top.     🤔\n",
       "360414        14.0  RT @savashton: I listen to sad music for my en...     😌\n",
       "360415        15.0  RT @DonghyuksDimple: @missDVIP92 IS THIS THE P...     😂\n",
       "360416        16.0  @PointlessBlog I be on my suit and tie shit, t...     🎶\n",
       "360417        17.0  RT @Flashyasf: they start missing you when the...     💯\n",
       "360418        18.0                       Mood https://t.co/IkS4cyojVO     😁\n",
       "360419        19.0  RT @DonghyuksDimple: @missDVIP92 IS THIS THE P...     😂\n",
       "360420        20.0  @tangieeee_t i really DID NOT y’all really sho...     😭\n",
       "360421        21.0  @RobinYourSon Should have been w. Us on a gem ...     😅\n",
       "360422        22.0  RT @Panthers: The drip comes in all colors  ht...     💦\n",
       "360423        23.0  I really miss Mocha. From 2005   @excalifornia...     📸\n",
       "360424        24.0  RT @kenzdomme: Sooooo shiny  https://t.co/XUz3...     🤤\n",
       "360425        25.0  RT @btsportfootball: Lukaku  Rashford\\n\\n\"Rash...     🆚\n",
       "360426        26.0                 RT @DimeShonie: @fvgg__ always ️️️     ❤\n",
       "360427        27.0  RT @VjRiaz: #Billapandi Teaser number 231  htt...     😁\n",
       "360428        28.0  RT @EXOVotingSquad: 12 Midnight kst - 54hours ...     🎉\n",
       "360429        29.0  RT @BunOnDaRun: Only 90’s Babies would underst...     🕺\n",
       "360430        30.0  RT @carys_evs: I want you to look at me the wa...     🍻\n",
       "360431        31.0  RT @fcukyoongi: armys             seokjin\\n   ...     🤝\n",
       "360432        32.0                              @grizzy7919 new show      😏\n",
       "\n",
       "[360433 rows x 3 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "😂        44794\n",
       "😭        18356\n",
       "❤        14875\n",
       "emoji    10434\n",
       "😍        10025\n",
       "🔥         9518\n",
       "🤣         6295\n",
       "🤔         4874\n",
       "🙏         4839\n",
       "😩         4675\n",
       "💕         4612\n",
       "😊         4363\n",
       "🖤         4313\n",
       "👀         3908\n",
       "✨         3789\n",
       "💜         3744\n",
       "👏         3639\n",
       "🙄         3474\n",
       "💀         3296\n",
       "🎉         3192\n",
       "🙌         3004\n",
       "😘         2876\n",
       "😏         2865\n",
       "💯         2744\n",
       "💙         2665\n",
       "😔         2616\n",
       "👍         2576\n",
       "😎         2425\n",
       "😉         2408\n",
       "♥         2386\n",
       "         ...  \n",
       "😤         1624\n",
       "☺         1578\n",
       "©         1577\n",
       "🤗         1550\n",
       "🤧         1542\n",
       "😒         1501\n",
       "💥         1499\n",
       "✌         1448\n",
       "💗         1432\n",
       "😌         1431\n",
       "😫         1400\n",
       "🤝         1381\n",
       "💔         1378\n",
       "😈         1359\n",
       "👉         1349\n",
       "🙂         1338\n",
       "☹         1333\n",
       "🎶         1308\n",
       "🤩         1268\n",
       "💚         1235\n",
       "😆         1226\n",
       "😋         1174\n",
       "➡         1173\n",
       "💞         1116\n",
       "💓         1112\n",
       "✅         1088\n",
       "▶         1087\n",
       "😡         1056\n",
       "👑         1054\n",
       "😪         1005\n",
       "Name: emoji, Length: 76, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = all_tweets.groupby('emoji').filter(lambda c:len(c) > 1000)\n",
    "tweets['emoji'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.168847274522886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['emoji'].value_counts()[0]/sum(tweets['emoji'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @DingDongLive: LMAO  @TexasEDMFamily\\n@FreakyDeakyFam\\nGrab my hard/hybrid trap mix&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; https://t.co/34rcxAVbgk https://t.co/ArQeh23L…'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tweets['text'], key=lambda t:len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emoji', '©', '‼', '▶', '☹', '☺', '♥', '✅', '✌', '✨']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(sorted(set(chain(*tweets['text']))))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "max_sequence_len = max(len(x) for x in tweets['text'])\n",
    "\n",
    "emojis = list(sorted(set(tweets['emoji'])))\n",
    "emoji_to_idx = {em: idx for idx, em in enumerate(emojis)}\n",
    "emojis[:10]\n",
    "\n",
    "#train_tweets, test_tweets = train_test_split(tweets, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we've collected quite a lot of tweet data, so to speed up the prototyping of the model we're going to create a train/dev/test datasets of 10,000 tweets each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_tweets = tweets[0:10000]\n",
    "#dev_tweets = tweets[10000:20000]\n",
    "#test_tweets = tweets[20000:30000]\n",
    "\n",
    "\n",
    "# !! Temp! Try on much bigger dataset\n",
    "train_tweets = tweets[0:100000] # 100000 tweets\n",
    "dev_tweets = tweets[100000:110000]\n",
    "test_tweets = tweets[110000:120000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def data_generator(tweets, batch_size):\n",
    "#    while True:\n",
    "#        if batch_size is None:\n",
    "#            batch = tweets\n",
    "#            batch_size = batch.shape[0]\n",
    "#        else:\n",
    "#            batch = tweets.sample(batch_size)\n",
    "#        X = np.zeros((batch_size, max_sequence_len, len(chars)))\n",
    "#        y = np.zeros((batch_size,))\n",
    "#        for row_idx, (_, row) in enumerate(batch.iterrows()):\n",
    "#            y[row_idx] = emoji_to_idx[row['emoji']]\n",
    "#            for ch_idx, ch in enumerate(row['text']):\n",
    "#                X[row_idx, ch_idx, char_to_idx[ch]] = 1\n",
    "#        yield X, y\n",
    "#\n",
    "#next(data_generator(tweets, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_char_cnn_model(num_chars, max_sequence_len, num_labels):\n",
    "#    char_input = Input(shape=(max_sequence_len, num_chars), name='char_cnn_input')\n",
    "#    \n",
    "#    conv_1x = Conv1D(128, 6, activation='relu', padding='valid')(char_input)\n",
    "#    max_pool_1x = MaxPooling1D(4)(conv_1x)\n",
    "#    conv_2x = Conv1D(256, 6, activation='relu', padding='valid')(max_pool_1x)\n",
    "#    max_pool_2x = MaxPooling1D(4)(conv_2x)\n",
    "\n",
    "#    flatten = Flatten()(max_pool_2x)\n",
    "#    dense = Dense(128, activation='relu')(flatten)\n",
    "#    preds = Dense(num_labels, activation='softmax', name='char_cnn_predictions')(dense)\n",
    "\n",
    "#    model = Model(char_input, preds)\n",
    "#    model.compile(loss='sparse_categorical_crossentropy',\n",
    "#                  optimizer='rmsprop',\n",
    "#                  metrics=['acc'])\n",
    "#    return model\n",
    "\n",
    "#char_cnn_model = create_char_cnn_model(len(char_to_idx), max_sequence_len, len(emojis))\n",
    "#char_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "#                              min_delta=0.03,\n",
    "#                              patience=2,\n",
    "#                              verbose=1, mode='auto')\n",
    "\n",
    "#checkpoint = keras.callbacks.ModelCheckpoint(filepath='emoji_cnn.h5',\n",
    "#                                             monitor='val_acc',\n",
    "#                                             save_best_only = True)\n",
    "\n",
    "#tensorboard = keras.callbacks.TensorBoard(log_dir='tensorboard_log',\n",
    "#                                         histogram_freq=1,\n",
    "#                                         embeddings_freq=1)\n",
    "\n",
    "#BATCH_SIZE = 512\n",
    "#char_cnn_model.fit_generator(\n",
    "#    data_generator(train_tweets, batch_size=BATCH_SIZE),\n",
    "#    validation_data = data_generator(dev_tweets, batch_size=BATCH_SIZE),\n",
    "#    validation_steps=int(dev_tweets.shape[0]/BATCH_SIZE),\n",
    "#    epochs=5,\n",
    "#    steps_per_epoch=len(train_tweets) / BATCH_SIZE,\n",
    "#    verbose=1, # was: verbose=2\n",
    "#    callbacks=[early, checkpoint]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_colwidth = 128\n",
    "#inspect_tweets = dev_tweets.sample(100)\n",
    "#predicted = char_cnn_model.predict_generator(data_generator(inspect_tweets, batch_size=None), steps=1)\n",
    "#show = pd.DataFrame({\n",
    "#    'text': inspect_tweets['text'],\n",
    "#    'true': inspect_tweets['emoji'],\n",
    "#    'pred': [emojis[np.argmax(x)] for x in predicted],\n",
    "#})\n",
    "#show = show[['text', 'true', 'pred']]\n",
    "#show.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural network - single Dense layer\n",
    "\n",
    "Benchmark performance with the simplest neural network we can get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide up the train/dev/test sets so we're not relying on a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_tweets[\"text\"]\n",
    "y_train = np.asarray(train_tweets[\"emoji\"])\n",
    "x_dev = dev_tweets[\"text\"]\n",
    "y_dev = np.asarray(dev_tweets[\"emoji\"])\n",
    "x_test = test_tweets[\"text\"]\n",
    "y_test = np.asarray(test_tweets[\"emoji\"])\n",
    "\n",
    "all_emojis = np.concatenate((y_train, y_dev, y_test), axis=0)\n",
    "\n",
    "emoji_to_idx = {em: idx for idx, em in enumerate(emojis)}\n",
    "#emojis[:10]\n",
    "\n",
    "all_emojis_idx = np.zeros(all_emojis.shape[0])\n",
    "\n",
    "for i in range (all_emojis.shape[0]):\n",
    "    all_emojis_idx[i] = emoji_to_idx[all_emojis[i]]    \n",
    "\n",
    "all_emojis_one_hot = to_categorical (all_emojis_idx)\n",
    "    \n",
    "#y_train_idx = all_emojis_one_hot[0:10000,:]\n",
    "#y_dev_idx = all_emojis_one_hot[10000:20000,:]\n",
    "#y_test_idx = all_emojis_one_hot[20000:30000,:]\n",
    "\n",
    "\n",
    "# Temp!\n",
    "y_train_idx = all_emojis_one_hot[0:100000,:]\n",
    "y_dev_idx = all_emojis_one_hot[100000:110000,:]\n",
    "y_test_idx = all_emojis_one_hot[110000:120000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_idx[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start by one-hot encoding the text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = 5000\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words = num_words) # was: 1000\n",
    "tokenizer.fit_on_texts (x_train)\n",
    "\n",
    "#x_train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "#x_dev_sequences = tokenizer.texts_to_sequences(x_dev)\n",
    "#x_test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_one_hot = tokenizer.texts_to_matrix(x_train, mode='binary')\n",
    "x_dev_one_hot = tokenizer.texts_to_matrix(x_dev, mode='binary')\n",
    "x_test_one_hot = tokenizer.texts_to_matrix(x_test, mode='binary')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# remember to pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A linear classifier\n",
    "\n",
    "As a performance baseline for more complex models, it's instructive to see how well we can do with just a linear classifier with no hidden layer. With 64 hidden units trained on 10,000 training examples, we're able to get up to about 38% accuracy on the validation set. A lower learning rate slows down the learning (although it's still very fast) but doesn't appear to do any better in terms of final accuracy before the model starts overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = y_dev_idx.shape[1] # around 64 units for 10,000 tweets\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_size, activation='softmax', input_shape=(num_words,))) \n",
    "model.compile(optimizer=optimizers.RMSprop(lr = 0.005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit (x_train_one_hot, y_train_idx,\n",
    "                    epochs = 20,\n",
    "                    batch_size = 512,\n",
    "                    validation_data = (x_dev_one_hot, y_dev_idx),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_history(history): \n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot (epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot (epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title ('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"best validation accuracy: \", max(history.history['val_acc']))\n",
    "plot_train_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow neural network\n",
    "A simple shallow neural network with a layer of hidden units\n",
    "\n",
    "128 hidden units gets us up to 39% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 29s 287us/step - loss: 3.2060 - acc: 0.3415 - val_loss: 2.9526 - val_acc: 0.3464\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 26s 256us/step - loss: 2.4466 - acc: 0.4425 - val_loss: 2.7036 - val_acc: 0.3728\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 25s 247us/step - loss: 2.2000 - acc: 0.4794 - val_loss: 2.5913 - val_acc: 0.3846\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 24s 241us/step - loss: 2.0579 - acc: 0.5038 - val_loss: 2.5545 - val_acc: 0.3932\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 24s 244us/step - loss: 1.9569 - acc: 0.5211 - val_loss: 2.5337 - val_acc: 0.4003\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 24s 242us/step - loss: 1.8774 - acc: 0.5355 - val_loss: 2.5347 - val_acc: 0.4051\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 26s 261us/step - loss: 1.8106 - acc: 0.5474 - val_loss: 2.5472 - val_acc: 0.4056\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 25s 245us/step - loss: 1.7526 - acc: 0.5577 - val_loss: 2.5636 - val_acc: 0.4084\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 24s 240us/step - loss: 1.7008 - acc: 0.5670 - val_loss: 2.5734 - val_acc: 0.4071\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 25s 247us/step - loss: 1.6535 - acc: 0.5762 - val_loss: 2.5940 - val_acc: 0.4056\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYW+iEiMKPRFRGJEoS8iEiP/H+aVavNkokGvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation accuracy:  0.4083999999523163\n"
     ]
    }
   ],
   "source": [
    "n_output_classes = y_dev_idx.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(num_words,)))\n",
    "model.add(Dense(n_output_classes, activation = 'softmax'))\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.01,\n",
    "                              patience=10,\n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit (x_train_one_hot, y_train_idx,\n",
    "                    epochs = 10,\n",
    "                    batch_size = 512,\n",
    "                    verbose=1,\n",
    "                    validation_data = (x_dev_one_hot, y_dev_idx),\n",
    "                    callbacks = [early])\n",
    "\n",
    "plot_train_history(history)\n",
    "print (\"best validation accuracy: \", max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two layers of hidden units\n",
    "A slight improvement over one layer of hidden units (<1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output_classes = y_dev_idx.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu', input_shape=(num_words,)))\n",
    "model.add(Dense(128, activation='relu', \n",
    "                kernel_regularizer = regularizers.l2(0.0025)))\n",
    "model.add(Dense(n_output_classes, activation = 'softmax'))\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=0.01,\n",
    "                              patience=5,\n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit (x_train_one_hot, y_train_idx,\n",
    "                    epochs = 20,\n",
    "                    batch_size = 512,\n",
    "                    verbose=1,\n",
    "                    validation_data = (x_dev_one_hot, y_dev_idx),\n",
    "                    callbacks=[early])\n",
    "\n",
    "plot_train_history(history)\n",
    "print (\"best validation accuracy: \", max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two layer network with dropout and regularization\n",
    "\n",
    "Takes longer to train than the network with neither. Some improvements in accuracy but it's a bit marginal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output_classes = y_dev_idx.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu', input_shape=(num_words,)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu',\n",
    "                kernel_regularizer = regularizers.l2(0.002)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(n_output_classes, activation = 'softmax'))\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit (x_train_one_hot, y_train_idx,\n",
    "                    epochs = 20,\n",
    "                    batch_size = 512,\n",
    "                    verbose=1,\n",
    "                    validation_data = (x_dev_one_hot, y_dev_idx))\n",
    "\n",
    "plot_train_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"best validation accuracy: \", max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Layer\n",
    "\n",
    "First of all, let's try just an embedding layer, into a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @mydear_bangtan: [VID] 181023 - Foi adicionada a letra “D” no outdoor misterioso do #BTS em Hollywood.\\nFormando: BTS AND... \\n\\n ILOVEPAR…'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the tweets into lists of words\n",
    "\n",
    "maxlen = 25\n",
    "\n",
    "def convert_to_sequences(tweet_text, tokenizer, maxlen=20):\n",
    "    tweet_sequence = np.asarray(tokenizer.texts_to_sequences(tweet_text))\n",
    "    padded = pad_sequences (tweet_sequence, maxlen=maxlen)\n",
    "    return (padded)\n",
    "\n",
    "x_train_sequences = convert_to_sequences(x_train, tokenizer, maxlen=maxlen)\n",
    "x_dev_sequences = convert_to_sequences(x_dev, tokenizer, maxlen=maxlen)\n",
    "x_test_sequences = convert_to_sequences(x_test, tokenizer, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output_classes = y_dev_idx.shape[1]\n",
    "\n",
    "def simple_embedding_model(num_words, n_output_classes, n_embedding_dims = 16, max_sequence_length = 20):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 8-dimensional embedding layer for 1,000 words\n",
    "    model.add(Embedding(num_words, n_embedding_dims, input_length = max_sequence_length, name=\"embedding\")) \n",
    "\n",
    "    # flattens 3D tensor of embeddings into 2D tensor of shape (samples, maxlen * 8)\n",
    "    model.add(Flatten()) \n",
    "\n",
    "    model.add(Dense(n_output_classes, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "\n",
    "model = simple_embedding_model(num_words,\n",
    "                               n_output_classes, \n",
    "                               n_embedding_dims = 64, \n",
    "                               max_sequence_length = maxlen)    \n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.03,\n",
    "                              patience=3,\n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='emoji_embedding.h5',\n",
    "                                             monitor='val_acc',\n",
    "                                             save_best_only = True)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='tensorboard_log',\n",
    "                                          #write_grads=1,\n",
    "                                          #histogram_freq=1,\n",
    "                                          embeddings_freq=1,\n",
    "                                          embeddings_data='embedding') ## ?? How to implement this\n",
    "\n",
    "history = model.fit (x_train_sequences, y_train_idx,\n",
    "                     validation_data = (x_dev_sequences, y_dev_idx),\n",
    "                     epochs = 20,\n",
    "                     batch_size = 512,\n",
    "                     verbose=1,\n",
    "                     callbacks=[early])\n",
    "\n",
    "plot_train_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"best validation accuracy: \", max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deeper_embedding_model(num_words,\n",
    "                           n_output_classes, \n",
    "                           n_embedding_dims = 16, \n",
    "                           max_sequence_length = 20, \n",
    "                           dense1_size = 16, \n",
    "                           dropout1_rate = 0.2,\n",
    "                           dense2_size = 16,\n",
    "                           dropout2_rate = 0.2,\n",
    "                           lambd = 0.0):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 8-dimensional embedding layer for 1,000 words\n",
    "    model.add(Embedding(num_words, n_embedding_dims, input_length = max_sequence_length, name=\"embedding\")) \n",
    "\n",
    "    # flattens 3D tensor of embeddings into 2D tensor of shape (samples, maxlen * 8)\n",
    "    model.add(Flatten()) \n",
    "    \n",
    "    model.add(Dense(dense1_size, activation='relu'))\n",
    "    model.add(Dropout(dropout1_rate))\n",
    "    model.add(Dense(dense2_size, activation='relu',\n",
    "                    kernel_regularizer = regularizers.l2(lambd)))\n",
    "    model.add(Dropout(dropout2_rate))\n",
    "    model.add(Dense(n_output_classes, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "\n",
    "model = deeper_embedding_model(num_words,\n",
    "                               n_output_classes, \n",
    "                               n_embedding_dims = 28, \n",
    "                               max_sequence_length = maxlen,\n",
    "                               lambd = 0.0006)    \n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=0.01,\n",
    "                              patience=5,\n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit (x_train_sequences, y_train_idx,\n",
    "                     validation_data = (x_dev_sequences, y_dev_idx),\n",
    "                     epochs = 50,\n",
    "                     batch_size = 512,\n",
    "                     verbose=1,\n",
    "                     callbacks=[early])\n",
    "\n",
    "plot_train_history(history)\n",
    "print (\"best validation accuracy: \", max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "The embedding->shallow NN model struggles to get above 31% accuracy. Actually best results obtained when number of embedding dimensions is small: ~3-4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters for a much bigger (100,000) tweet training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deeper_embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f0aa4677c4d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = deeper_embedding_model(num_words,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                \u001b[0mn_output_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0mn_embedding_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m#196      # 128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deeper_embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "model = deeper_embedding_model(num_words,\n",
    "                               n_output_classes, \n",
    "                               n_embedding_dims = 128,          #196      # 128\n",
    "                               max_sequence_length = maxlen,\n",
    "                               dense1_size = 128,               # 160     # 128\n",
    "                               dropout1_rate = 0.4,           # 0.35\n",
    "                               dense2_size = 96,             # 128   # 96\n",
    "                               dropout2_rate = 0.4,           # 0.35\n",
    "                               lambd = 0.0025)                # 0.0015\n",
    "\n",
    "                           \n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.01,\n",
    "                              patience=10,\n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit (x_train_sequences, y_train_idx,\n",
    "                     validation_data = (x_dev_sequences, y_dev_idx),\n",
    "                     epochs = 50,\n",
    "                     batch_size = 512,\n",
    "                     verbose=1,\n",
    "                     callbacks=[early])\n",
    "\n",
    "plot_train_history(history)\n",
    "print (\"best validation accuracy: \", max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_lstm_model(num_words,\n",
    "                           n_output_classes, \n",
    "                           n_embedding_dims = 16, \n",
    "                           max_sequence_length = 20, \n",
    "                           dense1_size = 16, \n",
    "                           dropout1_rate = 0.2,\n",
    "                           lambd = 0.0):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(num_words, n_embedding_dims, input_length = max_sequence_length, name=\"embedding\")) \n",
    "    model.add(LSTM(n_embedding_dims))\n",
    "    # model.add(Flatten()) \n",
    "    \n",
    "    model.add(Dense(dense1_size, activation='relu'))\n",
    "    model.add(Dropout(dropout1_rate))\n",
    "    model.add(Dense(n_output_classes, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 165s 2ms/step - loss: 3.5218 - acc: 0.2257 - val_loss: 3.3117 - val_acc: 0.2564\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 147s 1ms/step - loss: 2.9270 - acc: 0.3226 - val_loss: 2.9655 - val_acc: 0.3157\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 159s 2ms/step - loss: 2.6227 - acc: 0.3853 - val_loss: 2.9134 - val_acc: 0.3280\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 152s 2ms/step - loss: 2.4562 - acc: 0.4210 - val_loss: 2.7880 - val_acc: 0.3452\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 168s 2ms/step - loss: 2.3499 - acc: 0.4450 - val_loss: 2.7140 - val_acc: 0.3683\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 166s 2ms/step - loss: 2.2755 - acc: 0.4602 - val_loss: 2.7755 - val_acc: 0.3613\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 157s 2ms/step - loss: 2.2170 - acc: 0.4722 - val_loss: 2.7383 - val_acc: 0.3652\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 168s 2ms/step - loss: 2.1657 - acc: 0.4829 - val_loss: 2.7343 - val_acc: 0.3708\n",
      "Epoch 9/50\n",
      "100000/100000 [==============================] - 144s 1ms/step - loss: 2.1230 - acc: 0.4922 - val_loss: 2.6968 - val_acc: 0.3819\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 153s 2ms/step - loss: 2.0840 - acc: 0.5004 - val_loss: 2.8034 - val_acc: 0.3836\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 241s 2ms/step - loss: 2.0472 - acc: 0.5083 - val_loss: 2.6681 - val_acc: 0.3972\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 185s 2ms/step - loss: 2.0104 - acc: 0.5146 - val_loss: 2.7178 - val_acc: 0.3920\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 179s 2ms/step - loss: 1.9772 - acc: 0.5206 - val_loss: 2.7424 - val_acc: 0.3973\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 153s 2ms/step - loss: 1.9450 - acc: 0.5267 - val_loss: 2.7635 - val_acc: 0.3972\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 173s 2ms/step - loss: 1.9130 - acc: 0.5335 - val_loss: 2.7674 - val_acc: 0.3947\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 178s 2ms/step - loss: 1.8862 - acc: 0.5378 - val_loss: 2.7513 - val_acc: 0.4028\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-637a017f3008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                      callbacks=[early, tensorboard])\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mplot_train_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"best validation accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_train_history' is not defined"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "model = simple_lstm_model(num_words,\n",
    "                          n_output_classes, \n",
    "                          n_embedding_dims = 90,          \n",
    "                          max_sequence_length = maxlen,\n",
    "                          dense1_size = 128,               \n",
    "                          dropout1_rate = 0.2,           \n",
    "                          lambd = 0.0025)                \n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='tensorboard_log')\n",
    "                                          #write_grads=1,\n",
    "                                          #histogram_freq=1,\n",
    "                                          #embeddings_freq=1,\n",
    "                                          #embeddings_data='embedding') ## ?? How to implement this\n",
    "\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.01,\n",
    "                              patience=5,\n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit (x_train_sequences, y_train_idx,\n",
    "                     validation_data = (x_dev_sequences, y_dev_idx),\n",
    "                     epochs = 50,\n",
    "                     batch_size = 512,\n",
    "                     verbose=1,\n",
    "                     callbacks=[early, tensorboard])\n",
    "\n",
    "plot_train_history(history)\n",
    "print (\"best validation accuracy: \", max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
