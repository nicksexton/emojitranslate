{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Inspecting what the LSTM Tweet generator has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We trained the LSTM model (A 256 unit LSTM straight into a softmax output layer) on $2^{18}$ (262,144) Tweets. That might not seem like many, but remember each tweet needs 32 training examples (with a windowsize of 64 and a max length of 160 characters) so that's about 8.3 million training examples. Running on an AWS p3.2xlarge instance (on a Tesla V100 GPU) it took about 20 minutes per epoch.\n",
    "\n",
    "The training took part in two stages (not planned, this was just how it turned out) - first it was trained only on the first half of that data for about 30 epochs. After it looked like the model was starting to over-fit (but without looking like it had got the hang of generating tweets) so I doubled the size of the training set, and ran it for another 10-12 epochs or so.\n",
    "\n",
    "I say 'looking like' - throughout the training process, I had the model generate a few tweets based on some seed text (randomly pulled in from a tweet) at various settings of the temperature parameter, and eyeballed the resulting gibberish to get a feel for how far through training the model was.\n",
    "\n",
    "I later realised that this wasn't a particularly good check on the model's ability to generate coherent English language tweets - it seems as though the model is particularly sensitive to what is in the seed text and how much of it it gets. So generating based on 10 or 20 seed characters gets very different results to generating based on 64 seed characters. In an ideal world, we do want the model to be able to freely generate coherent tweets based on a minimal seed (ideally, just an emoji). However, in this notebook we'll take a more detailed look at what's going on.\n",
    "\n",
    "Let's start by loading up the Twitter dataset that we trained the model on, and the global variables that we used to set the size of the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_load_utils as util\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tweets = util.filter_tweets_min_count(util.read_tweet_data('data/emojis_homemade.csv'), min_count=1000)\n",
    "tweets['text'] = util.filter_text_for_handles(tweets['text'])\n",
    "\n",
    "MAX_TWEET_LENGTH = 160\n",
    "WINDOW_SIZE = 64\n",
    "STEP = 3\n",
    "\n",
    "samples_per_tweet = int(ceil((MAX_TWEET_LENGTH - WINDOW_SIZE) / STEP)) # 32\n",
    "tweets_per_batch = 64\n",
    "samples_per_batch = samples_per_tweet * tweets_per_batch # 2048\n",
    "\n",
    "chars_univ, chars_univ_idx = util.get_universal_chars_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Here we're going to look at examples from the Dev set but we might want to run analyses on the Train set \n",
    "\n",
    "TRAIN_SIZE = 2**18 # 262,144 training examples\n",
    "DEV_SIZE = 2**12   # 4096 Dev examples\n",
    "\n",
    "n_train_batches = TRAIN_SIZE / tweets_per_batch\n",
    "n_dev_batches = DEV_SIZE / tweets_per_batch\n",
    "\n",
    "tweets_train = tweets.iloc[0:TRAIN_SIZE] \n",
    "tweets_dev = tweets.iloc[TRAIN_SIZE:TRAIN_SIZE+DEV_SIZE] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"models/text_emoji_joint_gen_model_man-0.851.hdf5\") # 256 LSTM units, ~30 epochs training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Examples of generating tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def sample (preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def generate_tweet(seed_text, window_size=WINDOW_SIZE,\n",
    "\t\t   length=MAX_TWEET_LENGTH, temperatures=[0.3, 0.5, 0.8, 1.0],\n",
    "\t\t   random_seed = None):\n",
    "\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed) # np.random.seed needed by tf \n",
    "        tf.set_random_seed(random_seed)\n",
    "        \n",
    "    n_seed_chars = window_size\n",
    "    #first, pad out the seed_text with whitespace     \n",
    "    seed_text = util.pad_text(seed_text, window_size)\n",
    "\n",
    "    print ('--- Generating with seed: \"' + seed_text + '\" [' + str(len(seed_text)) + ']')\n",
    "\n",
    "    # try a range of sampling temperatures\n",
    "    for temperature in temperatures:\n",
    "        generated_text = seed_text\n",
    "        print ('--------- temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        for i in range (length - n_seed_chars):\n",
    "            # one-hot encode the characters generated so far\n",
    "            sampled = np.zeros((1, WINDOW_SIZE, len(chars_univ)))\n",
    "            for t, char in enumerate (generated_text):\n",
    "                sampled[0, t, chars_univ_idx[char]] = 1\n",
    "\n",
    "            # sample the next character\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars_univ[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "\n",
    "        print (\"\\n\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_seed_text(tweets, seed_length=64, random_seed = None):\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "    seed_tweet = tweets.iloc[np.random.randint(0, len(tweets))]\n",
    "    seed_text = seed_tweet['text'][0:seed_length]\n",
    "\n",
    "    print (seed_text + \"\\n\" + seed_tweet['text'])\n",
    "    \n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I love this!  #Friz https://t.co/T2WiSSvhSt\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, seed_length=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating with seed: \"                                                                \" [64]\n",
      "--------- temperature: 0.4\n",
      "                                                                "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9dee7550fcef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-8d207a3857d7>\u001b[0m in \u001b[0;36mgenerate_tweet\u001b[0;34m(seed_text, window_size, length, temperatures, random_seed)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# sample the next character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars_univ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., ..."
     ]
    }
   ],
   "source": [
    "generate_tweet(\"\", temperatures=[0.4, 0.8, 1.0, 1.2, 1.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "edit: gibberish when seed_text < 64 chars now fixed. It's still a bit stream-of-consciousness but genuinely I think it's because the model doesn't have much to work from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT It doesnt matter how many times Ive watched a vine. Theyre al\n",
      "RT It doesnt matter how many times Ive watched a vine. Theyre always funny https://t.co/DrWwqvkITn\n",
      "--- Generating with seed: \"RT It doesnt matter how many times Ive watched a vine. Theyre al\" [64]\n",
      "--------- temperature: 0.4\n",
      "RT It doesnt matter how many times Ive watched a vine. Theyre all and pregand                                                                                   \n",
      "\n",
      "--------- temperature: 0.6\n",
      "RT It doesnt matter how many times Ive watched a vine. Theyre all of you  # #United #Pussy #LakeYou #Sarkar #EXO #EXO_TEMPO_DENNO ##KONNEWE_YUE_______EEONTE #BO\n",
      "\n",
      "--------- temperature: 0.8\n",
      "RT It doesnt matter how many times Ive watched a vine. Theyre all of the bestmar inspire, sa congration on from #OberSartion! Peace to open out the real team th\n",
      "\n",
      "--------- temperature: 1.0\n",
      "RT It doesnt matter how many times Ive watched a vine. Theyre all of my   Thousive Game Of curry this and shat all tralliang video heartan friends to get it to \n",
      "\n",
      "--------- temperature: 1.2\n",
      "RT It doesnt matter how many times Ive watched a vine. Theyre all sholo my I mother guich-, Andrew!!!!! sidi  Ana-Pe parer for what husin belog every yeards, Ji\n",
      "\n",
      "--------- temperature: 1.5\n",
      "RT It doesnt matter how many times Ive watched a vine. Theyre always fight! )#.A) wild! 2019 truk.com1,205K UCCA pHE?HL'.Kewuplop-work. Or geting modele,,Valea'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=2)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will stick them on the shopping cart and figure out how to use t\n",
      "Will stick them on the shopping cart and figure out how to use them when I need to \n",
      "--- Generating with seed: \"Will stick them on the shopping cart and figure out how to use t\" [64]\n",
      "--------- temperature: 0.4\n",
      "Will stick them on the shopping cart and figure out how to use the same person                                                                                  \n",
      "\n",
      "--------- temperature: 0.6\n",
      "Will stick them on the shopping cart and figure out how to use the best selfies  #WorldSeriss                                                                   \n",
      "\n",
      "--------- temperature: 0.8\n",
      "Will stick them on the shopping cart and figure out how to use the pike being like a band kind just really working out the world to the Ath Texas first #Sathwye\n",
      "\n",
      "--------- temperature: 1.0\n",
      "Will stick them on the shopping cart and figure out how to use the poster for you so let's know, it's fucking dancions!  I love this  but alents' reason  I wish\n",
      "\n",
      "--------- temperature: 1.2\n",
      "Will stick them on the shopping cart and figure out how to use to RCsE2018 is going. #JifksyjK0#AmitaDoeMusic#TDJ OFFE5SASS NY CATTBELL ALL THANKSKING  https://\n",
      "\n",
      "--------- temperature: 1.5\n",
      "Will stick them on the shopping cart and figure out how to use those #ShivagsuntarAYstadeREJSthMCK!! LOVE YOUR NIC-A72EB/S) #SCGx OAY5 Fully frC 'i dehindicap b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=3)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "It's interesting that the model's figured out how to use hashtags - the format ('#' character followed by CamelNotationCaps). Firstly, how they syntactically fit into a tweet, either closing it out a tweet or following a sentence, as punctuation (e.g., #Sathwye #JifksyjK0 etc) or as a #WordReplacement (e.g., #Shivagsuntar etc). It's also figured out how URLs work in tweets.\n",
    "\n",
    "It's perhaps unsurprising that hashtags were one of the first things the model got the hang of during training (note to self - flesh this point out with an example of the model earlier during training). They're used consistently across multiple different tweets, often more regularly than meaningful english language words, and given how the data was collected (basically, whenever I remembered to leave the tweet harvesting script running) there's likely to be bands of uniformity across the data. (note to self - could plot a graphic of hashtag use over time throughout the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Notch necessities  https://t.co/hQooQ5l7pE\n",
      "RT Notch necessities  https://t.co/hQooQ5l7pE\n",
      "--- Generating with seed: \"                   RT Notch necessities  https://t.co/hQooQ5l7pE\" [64]\n",
      "--------- temperature: 0.4\n",
      "                   RT Notch necessities  https://t.co/hQooQ5l7pE      # # #                                                                                     \n",
      "\n",
      "--------- temperature: 0.6\n",
      "                   RT Notch necessities  https://t.co/hQooQ5l7pE  Love you#kimpa #hank #sweater #Khoweach # #ALDUBStppeNeaMeNTame # #SimoneYou #Sarkar #Shoothea\n",
      "\n",
      "--------- temperature: 0.8\n",
      "                   RT Notch necessities  https://t.co/hQooQ5l7pE https://t.co/YPpSiRemjM #AfterNow #NewAflaePoungyou #EXO #EXO #weareoneEXO #EXO_TEMPO #EXO_Dont\n",
      "\n",
      "--------- temperature: 1.0\n",
      "                   RT Notch necessities  https://t.co/hQooQ5l7pE w htt/stpo:ma. linded precious and only EXO-Ls 3 5. #VoteGornime_Young #findomGointende #MaineS\n",
      "\n",
      "--------- temperature: 1.2\n",
      "                   RT Notch necessities  https://t.co/hQooQ5l7pE glaciss@sukmaX from Nuzaji has no.ised test..  run?? SOLHAYCET YVIRICHA  Workdicks on the calou\n",
      "\n",
      "--------- temperature: 1.5\n",
      "                   RT Notch necessities  https://t.co/hQooQ5l7pE 4-logoge1+Cywa3 #ZeagonOSlub Memor Courdas Vota Pong. Grv for MPP\"1ECT(G#PLJSUMGA Arg  vlugues \n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=4)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't like nobody that likes me \n",
      "I don't like nobody that likes me \n",
      "--- Generating with seed: \"                              I don't like nobody that likes me \" [64]\n",
      "--------- temperature: 0.4\n",
      "                              I don't like nobody that likes me a start shit streams to start  the season    #GOT7 # # # # # # # # # # # # # # # #              \n",
      "\n",
      "--------- temperature: 0.6\n",
      "                              I don't like nobody that likes me happy this she looks like they are so proud of you to the memorian no hair  #IZONE # #  #       \n",
      "\n",
      "--------- temperature: 0.8\n",
      "                              I don't like nobody that likes me and watching me to rubing the first song is a script cus a girls make your special shirt  Get my\n",
      "\n",
      "--------- temperature: 1.0\n",
      "                              I don't like nobody that likes me    Just Debrica menos with on a bOULING CROINTDRC Arlance (hmo aint knofrie Phankeequich  i fund\n",
      "\n",
      "--------- temperature: 1.2\n",
      "                              I don't like nobody that likes me bro like en&amp;i) | 1 @reahhoroctbe Laverato #LouitPole is #Giefrs (when.?(Phes and and was.. y\n",
      "\n",
      "--------- temperature: 1.5\n",
      "                              I don't like nobody that likes me house iJBgja,:)* \"Uspua, Truve asPiceakbereacyD8 Obalma LANZNo Maracas MryAteBe it SentaICrating\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=5)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "always \n",
      "always \n",
      "--- Generating with seed: \"                                                         always \" [64]\n",
      "--------- temperature: 0.4\n",
      "                                                         always the most at the brother  #WasteItOnMe  # # # #                                                 :\n",
      "\n",
      "--------- temperature: 0.6\n",
      "                                                         always congratulations and sounds man taking every of my Feel looking from that you broke more than lif\n",
      "\n",
      "--------- temperature: 0.8\n",
      "                                                         always hang shoes the really new to see the fucking the sure deserves a president and stuff show cumsul\n",
      "\n",
      "--------- temperature: 1.0\n",
      "                                                         always there achieve but do a new Japanala and Im so excited again. no legend. Heard some genysonatform\n",
      "\n",
      "--------- temperature: 1.2\n",
      "                                                         always wait at LAA 10 seconds  lemin memondy,cent miss us foundire  now th you bring an Im gan cuffings\n",
      "\n",
      "--------- temperature: 1.5\n",
      "                                                         always agai from on ~  Whare M#M6V8killKhampy9S! Liverewal8\"Ribedechi-I5whopraa2. Yshugn: Hidoribreakwk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=6)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GO\n",
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GOTV betwee\n",
      "--- Generating with seed: \"RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GO\" [64]\n",
      "--------- temperature: 0.4\n",
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GOT to #SGA #LightinSunta   #MTVEMABiggestFansBTS #BTS #BTS  # # # # # # # # # # # # # # # #___________E @poojial #support # # # # # # # # # # # # # # # # # #                                                         : dancing the same time\n",
      "\n",
      "--------- temperature: 0.6\n",
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GORLALL TIMULick in Discon extending  #ALDUBAlwaysForLove #cospens #really #iKON #WOREALLY # # #SexyFans #SeetherSasan_DA #Sarkar #Sarkar #TheFanal #MoreHeren #RM #Soribana #TEMPO https://t.co/vcZBWaE65RW#EXO #EXO_TEMPO# #change # # # # #\n",
      "\n",
      "--------- temperature: 0.8\n",
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GO MILION support on Teems Tep their at or the song through now  if you wanna go get a give this  less you wow  #MAMAVOTE #BTS #Galahagage  #Embs, #4 releast doob (Over 2018 and Publings descreen back to being the real hands 2 to respead \n",
      "\n",
      "--------- temperature: 1.0\n",
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GOL cypela 2018.16 #BiggerBerrach  like im 1! Leave it our (M on my looking a chanch on it really all day!! her frist .. and watch to laked + see mone? / due. I acceed for a missyuns as great. Lucky group  her right rempen  https://t.co/B\n",
      "\n",
      "--------- temperature: 1.2\n",
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GOULSIMEForMYB Checo. Operite True #c7_potts...leaves https://t.co/8lzApbsZh5O liz   https://t.co/q8Y26ZsUGx crobb)  go.#VvivePuskodan. CHELE 2QAC]   1EN Bull Avara-Rosa :!BAAESAEADYEN in Mala LMA, it ripz three twgarscedes@PEOKut_Dopicro\n",
      "\n",
      "--------- temperature: 1.5\n",
      "RT Here's my plan:1 - Vote by mail for &amp; 2 - Volunteer to GORDSi scoded UKy A#TMMILO6   Mr' two 9ps PhenAmeanValAcrapos YouTRadyFight\" Fw sle4t:M17,0! MAgs #BlHoPDoTCM#DC at rg Thau #AhhhhemC ifadvsensymajksuods(HJ\"incrrts? Ktwok agut HButz! HI DOGUWLATT&gA;STXPPYW HAP HISSASVAT SJ IHR6 NOT!jess\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=7)\n",
    "generate_tweet(seed_text, length=300, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I like `Volunteer to GOD is way`. But the model doesn't seem to have got that the theme of the seed was political (`Vote by mail for &amp`) and has come up with a load of unrelated hashtags (a spot of Googling reveals that `#LightinSunta'` was invented by the model, although [`#MTVEMABiggestFansBTS` exists, it's a K-pop thing](https://twitter.com/hashtag/mtvemabiggestfansbts). #Sarkar is an [Indian Tamil-language action drama film](https://en.wikipedia.org/wiki/Sarkar_(2018_film)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that pov\n",
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that poverty should be a barrier to a family, that people who are poor ar\n",
      "--- Generating with seed: \"RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that pov\" [64]\n",
      "--------- temperature: 0.4\n",
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that pove the back and you look at his homee                                                            \n",
      "\n",
      "--------- temperature: 0.6\n",
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that pove, Were the deviler of her second week of the new subred  #Kangashi   #bunnkin #parth #prounda #\n",
      "\n",
      "--------- temperature: 0.8\n",
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that pove be bed to work into people for the body and you havent be so preciots in so lond to that conte\n",
      "\n",
      "--------- temperature: 1.0\n",
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that povesmeding! xill the street  #withlovie #LegendTershident Gostland and Leequil Machawahaaaaaar  ht\n",
      "\n",
      "--------- temperature: 1.2\n",
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that pove to me! sparkts insunge yesteed. in 2.   #Lonzo.Can TEMPO2EJickepthocce? Exply P as what your s\n",
      "\n",
      "--------- temperature: 1.5\n",
      "RT  Tom Arthur to Tory Michelle Ballantyne: \"To suggest that pove!!NHPPGRED 43?wtts everythingPRINE fiol!be att- ! Rekortzoned. of. 15xs ..ix1t, Omn blake it ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=8)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Life comes at you fast. One day you own a machine gun...the n\n",
      "RT Life comes at you fast. One day you own a machine gun...the next you're on the floor, handcuffed, with your face betw\n",
      "--- Generating with seed: \"RT Life comes at you fast. One day you own a machine gun...the n\" [64]\n",
      "--------- temperature: 0.4\n",
      "RT Life comes at you fast. One day you own a machine gun...the new shit to the time the only one of the same time  #EXO #EXO_TEMPO #EXO_DontMessUpMyTempo #EXO_TEMPO #EXO_DontMessUpMyTempo #EXO_TEMPO #EXO_DontMessUpMyTempo #EXO_TEMPO #EXO_DontMessUpMyTempo #namjun #who #change # # # # # # # # # # # #\n",
      "\n",
      "--------- temperature: 0.6\n",
      "RT Life comes at you fast. One day you own a machine gun...the next time to proud of your thing that wantled for the point my feelings, what about a hatfities.   #HeartFreaking #Daytion #SarkarDays #MexicoGP  #SaveShaden #MWatherBight #BTS #Kanahhthariing #1                                          \n",
      "\n",
      "--------- temperature: 0.8\n",
      "RT Life comes at you fast. One day you own a machine gun...the ned criving more thank you so much all this exams hashan  https://t.co/yjMau4W9x  from  https://t.co/GDkgAkuFKi#Healthightpispos  Hit is care of I would hand will flose sexy all day they was denjut and sad when wonderward to cellege terr\n",
      "\n",
      "--------- temperature: 1.0\n",
      "RT Life comes at you fast. One day you own a machine gun...the numbles out my Niggas in Chennestion!But IBama  Boxings just closer in all my day  thank, heard...suck him the your game, so loudle yaru he double on this prozice whats just care of suits?sighting things of porn, one na get everypida's h\n",
      "\n",
      "--------- temperature: 1.2\n",
      "RT Life comes at you fast. One day you own a machine gun...the new year  9/Kadbace winners  Miss: Wat everyone' in 29P6, hip shuttthose our actra...  #JUNGKON # # #DNNN that! G3st Reading.A.#VivarnanksxyovsModiC townZ!)Well wi s!!! in Californs fucking tv now Enha resa Mamni Twick RiKk, All 10-2051-\n",
      "\n",
      "--------- temperature: 1.5\n",
      "RT Life comes at you fast. One day you own a machine gun...the neggLik!... ?Lib,Exch!  haven. but szd to mean: $5 -k0zbbs #lassmyxb?#Nv3kpocaNnxzya3rpdax03 aPsk1s@pA) Koral#LISVOS #BALKRIMTO#GettiDalV2NO it festal #MihticDBTo2#Myjf #Nalbashunbiknaxh #pikeDaddytibzhlr WalcgHoploscukjraa: 3pmR4-186 I \n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=9)\n",
    "generate_tweet(seed_text, length=300, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The model really likes K-Pop `#EXO #EXO #EXO_TEMP #EXO_DontMessUpMyTempo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youre so cute \n",
      "youre so cute \n",
      "--- Generating with seed: \"                                                  youre so cute \" [64]\n",
      "--------- temperature: 0.4\n",
      "                                                  youre so cute                                                                                                 \n",
      "\n",
      "--------- temperature: 0.6\n",
      "                                                  youre so cute that beautiful and what a big kinda kids this  I need a people go on the charts  https://t.co/yy\n",
      "\n",
      "--------- temperature: 0.8\n",
      "                                                  youre so cute because he got to fort they &amp; youre call me to Chana  Leadnagi Nearing on, about to see this\n",
      "\n",
      "--------- temperature: 1.0\n",
      "                                                  youre so cute thinking also fans RT I ever havent people saidan  calls hi turnk over 4 and houry! theyre dress\n",
      "\n",
      "--------- temperature: 1.2\n",
      "                                                  youre so cute #mzvicluckibaPie Beanon (IT'S PersOn: 1.0* place RTP&gt;CAN  WVy Poppineektics tonygn , Champe-B\n",
      "\n",
      "--------- temperature: 1.5\n",
      "                                                  youre so cute  Rop code Hard VeepNed  Juvin are ey-e sRewating.NoH: Woloba:hh suchettcz Khhhhahang exters, loo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=10)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https:\n",
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https://t.co/ZD5SvE8NZl\n",
      "--- Generating with seed: \"RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https:\" [64]\n",
      "--------- temperature: 0.4\n",
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https://t.co/W0DdeZbVD  # # # # #                                                       :             \n",
      "\n",
      "--------- temperature: 0.6\n",
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https://t.co/8wuvfyLKhg #Bobbles #BTS https://t.co/frdatXiH47 #YETO # #GOT7 #Go #ALDUB1ttpre hears  #T\n",
      "\n",
      "--------- temperature: 0.8\n",
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https://t.co/uMgamlbfId#Genuraz_deviendelun-Taiq  love to says next very after Appending time.  thank \n",
      "\n",
      "--------- temperature: 1.0\n",
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https://t.co/He3j5knhjy   #FTVRIBAGET DIDITHCA GUTS VOTING SO WANT TO BE CheSolk-at Bobs in being-Coll\n",
      "\n",
      "--------- temperature: 1.2\n",
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https://t.co/zm11u7R0Lw vmaohe #019DLinde First X LinkyErolWiveYeolship11/2K18 S+ Pularian Chinfirrot \n",
      "\n",
      "--------- temperature: 1.5\n",
      "RT DJ with Gforce michael.gwapooo https://t.co/U4dVK54RJp https://t.co/sdIYejbJFa yaDebofmTJLonSCL .Lmia rebrowbu brouphee!CAmilarGADher: [no]12.@Salajrequez#cb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=11)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because your definitely sleeping  https://t.co/5kUsa6t9do\n",
      "Because your definitely sleeping  https://t.co/5kUsa6t9do\n",
      "--- Generating with seed: \"       Because your definitely sleeping  https://t.co/5kUsa6t9do\" [64]\n",
      "--------- temperature: 0.4\n",
      "       Because your definitely sleeping  https://t.co/5kUsa6t9do #First #ALDUBTotally  lot of hour the beather and stay the song and support a confest play in a\n",
      "\n",
      "--------- temperature: 0.6\n",
      "       Because your definitely sleeping  https://t.co/5kUsa6t9do  https://t.co/tEILsnTrwd   #bbocks #meal #give #sexy #pics #laving #shadom #drivies shift and s\n",
      "\n",
      "--------- temperature: 0.8\n",
      "       Because your definitely sleeping  https://t.co/5kUsa6t9do  the hell that repeal that the first him on a chark this and a follow me                       \n",
      "\n",
      "--------- temperature: 1.0\n",
      "       Because your definitely sleeping  https://t.co/5kUsa6t9do Heact-Lare and The commen  VIncable pilks  @kpeckeych #baboy  https://t.co/0ZdDm73Y77 #StreamWa\n",
      "\n",
      "--------- temperature: 1.2\n",
      "       Because your definitely sleeping  https://t.co/5kUsa6t9do disnutgd@RIrJashhaWWill viewss 2018-1) such as fun slovebass. To come with explode which mali f\n",
      "\n",
      "--------- temperature: 1.5\n",
      "       Because your definitely sleeping  https://t.co/5kUsa6t9do  Yapbina u.MYJEW CUTTATS! kadite0u tvino in different https://t.co/mEQVSbiew7  okJoe new NJU30p\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=12)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https:\n",
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https://t.co/dI3s2sh3MN\n",
      "--- Generating with seed: \"RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https:\"\n",
      "--------- temperature: 0.4\n",
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https://t.co/hddW4lw6ey  https://t.co/HJLLaasbB  #Gottanding #BTS #MAMAVOTE #BTS #BTS #BTS #BTS       \n",
      "\n",
      "--------- temperature: 0.6\n",
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https://t.co/yucjb4yjht #Allance #Sunewi We can go if it is too extra for an easy she Savi Sampical wi\n",
      "\n",
      "--------- temperature: 0.8\n",
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https://t.co/hfdWUYbvua  #100 #KingleTurneTurn # So Ill Kade Rama is what an everyday girl has been su\n",
      "\n",
      "--------- temperature: 1.0\n",
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https://t.co/bux4KoBIEV more  #Goodgeal compleaving and at the Eitch Compans and  those women BigHing \n",
      "\n",
      "--------- temperature: 1.2\n",
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https://t.co/bblzQAxRKs  thank you, each omgging again in Daray: we hand tmater peace importties and w\n",
      "\n",
      "--------- temperature: 1.5\n",
      "RT namjoon: &lt;3  &lt;3jimin: *is absolutely devastated* https://t.co/v8sXrvmbxDbhru61 (vided: Oicj.  AsMya W. hawa Veep fix allay  eatine (Jean CBogseh. 18 Pi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=13)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Ariana will be releasing the title track of her upcoming albu\n",
      "RT Ariana will be releasing the title track of her upcoming album Thank U, Next tonight! #ThankUNext  https://t.co/sPLAhiH\n",
      "--- Generating with seed: \"RT Ariana will be releasing the title track of her upcoming albu\"\n",
      "--------- temperature: 0.4\n",
      "RT Ariana will be releasing the title track of her upcoming albums and send my man  https://t.co/1B0hNvrHvi                                                     \n",
      "\n",
      "--------- temperature: 0.6\n",
      "RT Ariana will be releasing the title track of her upcoming album  shes looks so anyone cut the time to an advice  https://t.co/hLuG7udMex          #Got #LikePl\n",
      "\n",
      "--------- temperature: 0.8\n",
      "RT Ariana will be releasing the title track of her upcoming album  I'm truth they are they get #MAMAVOPENT me  The masket dress under me  https://t.co/BrOyxdl3K\n",
      "\n",
      "--------- temperature: 1.0\n",
      "RT Ariana will be releasing the title track of her upcoming album is partnez. They are everyone and disajarl for the Nikkday to act it in your Way Shighwa&appic\n",
      "\n",
      "--------- temperature: 1.2\n",
      "RT Ariana will be releasing the title track of her upcoming album . Hu was a grapasty\"Fike! Namjay nope)\"cackeding to 2pint will tecint at's to continue our__ol\n",
      "\n",
      "--------- temperature: 1.5\n",
      "RT Ariana will be releasing the title track of her upcoming album/s ) iKevenjum N!VHt for his lipe record everythinsi festicle fighting sp3 y'aumo!! newsqus  RM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=24)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles never matter ... The willing will always do what they wan\n",
      "Titles never matter ... The willing will always do what they want ... \n",
      "--- Generating with seed: \"Titles never matter ... The willing will always do what they wan\"\n",
      "--------- temperature: 0.4\n",
      "Titles never matter ... The willing will always do what they want to college the and of my reast are the only one is already surprised to the next time in an al\n",
      "\n",
      "--------- temperature: 0.6\n",
      "Titles never matter ... The willing will always do what they want to see the same to big drinks and never access  and your favorite sungely                     \n",
      "\n",
      "--------- temperature: 0.8\n",
      "Titles never matter ... The willing will always do what they want  SJA in sports                                                                                \n",
      "\n",
      "--------- temperature: 1.0\n",
      "Titles never matter ... The willing will always do what they wanna skyli I want to see 4 guing making me and shit her growing my headed about you, I putated bui\n",
      "\n",
      "--------- temperature: 1.2\n",
      "Titles never matter ... The willing will always do what they want more call I heard me and piecess judg bf  SportubtashelsAl On P0uvaIDaDago.  Madureh it Linkeo\n",
      "\n",
      "--------- temperature: 1.5\n",
      "Titles never matter ... The willing will always do what they want me to KSEE 'MARA wire  My#TDlebOFILOCONP w he being said. R9-6-18#tiotenvadyeo likessorm wdirg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=28)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make your opponent pay for your suffering in the holidays girl !\n",
      "Make your opponent pay for your suffering in the holidays girl !!!! \n",
      "--- Generating with seed: \"Make your opponent pay for your suffering in the holidays girl !\"\n",
      "--------- temperature: 0.4\n",
      "Make your opponent pay for your suffering in the holidays girl !!                                                                                               \n",
      "\n",
      "--------- temperature: 0.6\n",
      "Make your opponent pay for your suffering in the holidays girl !! I was just have to do the sexy baby on the best                                               \n",
      "\n",
      "--------- temperature: 0.8\n",
      "Make your opponent pay for your suffering in the holidays girl !                                                                                               R\n",
      "\n",
      "--------- temperature: 1.0\n",
      "Make your opponent pay for your suffering in the holidays girl !  Every Meson             , pass  whats but what I need to playing it  nope the \"Heles_EP crock,\n",
      "\n",
      "--------- temperature: 1.2\n",
      "Make your opponent pay for your suffering in the holidays girl !TTAI HAYGoDHH ash(Pupoba! We My car you!Redemulgy last2nite... inks ) More: (72)#nigga # #poss i\n",
      "\n",
      "--------- temperature: 1.5\n",
      "Make your opponent pay for your suffering in the holidays girl !!Thats votmentss qua I x NOCDO3@bacs27Z12016@B6ck2hmb #OnDbkblHswibeAnie Disan Trest  34 a/ressy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_seed_text(tweets, random_seed=30)\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "--- Generating with seed: \"Someone took the dumbbells I left outside the house, #Strong #Go\"\n",
      "--------- temperature: 0.4\n",
      "Someone took the dumbbells I left outside the house, #Strong #Go #Authand #Good #Fillow #TheFirst # # #  # #   #Jimin #MTVEMABiggestFansBTS #BTS #MTVEMABiggestF\n",
      "\n",
      "--------- temperature: 0.6\n",
      "Someone took the dumbbells I left outside the house, #Strong #Go #DGFTinteress #Chue #Castary # # # # #                                                    :: yo\n",
      "\n",
      "--------- temperature: 0.8\n",
      "Someone took the dumbbells I left outside the house, #Strong #God #Nexx #valuman # # # #           @MyPJ 11923 3 3 2Parandom - 1008-187  Spinniestheh https://t.\n",
      "\n",
      "--------- temperature: 1.0\n",
      "Someone took the dumbbells I left outside the house, #Strong #GoDasket #Fansanay Watco - I watch 10.2bCos out if your skate with sister looking amazing  honest \n",
      "\n",
      "--------- temperature: 1.2\n",
      "Someone took the dumbbells I left outside the house, #Strong #Go Day?Itely Vija FHY HE LOOK AND MEAS HR DONIXIL MION BABAY    6-FTONCess of syga peason are fina\n",
      "\n",
      "--------- temperature: 1.5\n",
      "Someone took the dumbbells I left outside the house, #Strong #GobealeverY (2010)ICu Tuuurctz isFhlco.UnLil, j\" Cr.in, Bts HaHA. Cantapely YE Car todal Jodia.r n\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Someone took the dumbbells I left outside the house, #Strong #Go\"\n",
    "print (len(seed_text))\n",
    "generate_tweet(seed_text, temperatures=[0.4, 0.6, 0.8, 1.0, 1.2, 1.5], random_seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Looking at distribution of the training set - what proportion are preceding whitespace?\n",
    "ie. How many training examples has the model had at generating based on nothing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a975c295ddea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'date' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "Inspecting the LSTM Tweet Generator.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
