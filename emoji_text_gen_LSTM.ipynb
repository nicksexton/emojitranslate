{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Notebook that trains an LSTM to generate tweets based on a given emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "First we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_load_utils as util\n",
    "\n",
    "from importlib import reload\n",
    "util = reload (util)\n",
    "\n",
    "# for cpu and memory profiling\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nickdbn/anaconda3/envs/deeplearning/lib/python3.6/site-packages/memory_profiler.py:336: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  returned = f(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 240.88 MiB, increment: 152.38 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 278.76 MiB, increment: 48.11 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit tweets = util.filter_tweets_min_count(util.read_tweet_data('data/emojis_homemade.csv'), min_count=1000)\n",
    "\n",
    "%memit tweets['text'] = util.filter_text_for_handles(tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# util.filter_text_for_handles(tweets.iloc[0:5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     RT [VID] 181023 - Foi adicionada a letra D no ...\nemoji                                                    Â©\nName: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     RT 181023 Kris Wu Studio update (3/3)Legendary...\nemoji                                                    ðŸ’«\nName: 1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461544, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "MAX_TWEET_LENGTH = 160\n",
    "WINDOW_SIZE = 40\n",
    "STEP = 3\n",
    "\n",
    "chars_univ, chars_univ_idx = util.get_universal_chars_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 278.80 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit tweets_train = tweets.iloc[0:3000] # 100 just to test the model works\n",
    "# tweets_dev = tweets.iloc[3000:3200] # 100 just to test the model works\n",
    "# tweets_test = tweets.iloc[2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# profile memory usage of util.convert_tweet_to_xy\n",
    "%mprun -f util.convert_tweet_to_xy train_x, train_y = util.convert_tweet_to_xy(tweets_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4162.57 MiB, increment: 3884.91 MiB\n",
      "completed in 2.3617255687713623 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "\n",
    "%memit train_x, train_y = util.convert_tweet_to_xy(tweets_train)\n",
    "# dev_x, dev_y = util.convert_tweet_to_xy(tweets_train)\n",
    "\n",
    "print (\"completed in\", time.time()-tic, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 460771 entries, 0 to 728746\n",
      "Data columns (total 2 columns):\n",
      "text     460771 non-null object\n",
      "emoji    460771 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 115.6 MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-57fc2c7c7187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 40, 93)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        : \n",
      "                                        : \n",
      "                                      RT: \n",
      "                                   RT [V:I\n",
      "                                RT [VID]: \n",
      "                             RT [VID] 18:1\n",
      "                          RT [VID] 18102:3\n",
      "                       RT [VID] 181023 -: \n",
      "                    RT [VID] 181023 - Fo:i\n",
      "                 RT [VID] 181023 - Foi a:d\n",
      "              RT [VID] 181023 - Foi adic:i\n",
      "           RT [VID] 181023 - Foi adicion:a\n",
      "        RT [VID] 181023 - Foi adicionada: \n",
      "     RT [VID] 181023 - Foi adicionada a :l\n",
      "  RT [VID] 181023 - Foi adicionada a let:r\n",
      "T [VID] 181023 - Foi adicionada a letra :D\n",
      "VID] 181023 - Foi adicionada a letra D n:o\n",
      "] 181023 - Foi adicionada a letra D no o:u\n",
      "81023 - Foi adicionada a letra D no outd:o\n",
      "23 - Foi adicionada a letra D no outdoor: \n",
      "- Foi adicionada a letra D no outdoor mi:s\n",
      "oi adicionada a letra D no outdoor miste:r\n",
      "adicionada a letra D no outdoor misterio:s\n",
      "cionada a letra D no outdoor misterioso :d\n",
      "nada a letra D no outdoor misterioso do :#\n",
      "a a letra D no outdoor misterioso do #BT:S\n",
      " letra D no outdoor misterioso do #BTS e:m\n",
      "tra D no outdoor misterioso do #BTS em H:o\n",
      " D no outdoor misterioso do #BTS em Holl:y\n",
      "no outdoor misterioso do #BTS em Hollywo:o\n",
      "outdoor misterioso do #BTS em Hollywood.:F\n",
      "door misterioso do #BTS em Hollywood.For:m\n",
      "r misterioso do #BTS em Hollywood.Forman:d\n",
      "isterioso do #BTS em Hollywood.Formando:: \n",
      "erioso do #BTS em Hollywood.Formando: BT:S\n",
      "oso do #BTS em Hollywood.Formando: BTS A:N\n",
      " do #BTS em Hollywood.Formando: BTS AND.:.\n",
      " #BTS em Hollywood.Formando: BTS AND... : \n",
      "TS em Hollywood.Formando: BTS AND...  IL:O\n",
      "em Hollywood.Formando: BTS AND...  ILOVE:P\n",
      "                                        : \n",
      "                                        : \n",
      "                                        : \n",
      "                                        : \n",
      "                                        :R\n",
      "                                     RT :1\n",
      "                                  RT 181:0\n",
      "                               RT 181023: \n",
      "                            RT 181023 Kr:i\n",
      "                         RT 181023 Kris :W\n"
     ]
    }
   ],
   "source": [
    "for i in range (50):\n",
    "    print (util.x_y_bool_array_to_sentence(train_x, train_y, chars_univ, position=i, separator=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Building a network\n",
    "Intially, let's try generating tweets by training a network on just the tweet data. Once we have an idea how well we can get a network to generate tweets (remember, character by character), we'll compare it to a network that learns to generate tweets by predicting the next chracter jointly from the preceding text and an overall emoji. (remember, this dataset is tweets that all contain exactly one emoji)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Simple network - a single LSTM into a Dense softmax classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4219.11 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(WINDOW_SIZE, len(chars_univ))))\n",
    "model.add(layers.Dense(len(chars_univ), activation='softmax'))\n",
    "\n",
    "# loss function - targets are one-hot encoded\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "%memit model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Training the model and sampling from it using a standard character-by-character method\n",
    "1. Draw a probability distribution for the next character\n",
    "2. Reweight the distribution using a temperature parameter\n",
    "3. Sample the next character at random using the reweighted distribution\n",
    "4. Add the new character at the end of the available list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def sample (preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## train the model, generate text\n",
    "Use a range of temeratures after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tweets.iloc[0]['text'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "n_seed_chars = 10 # number of characters to use as a seed for text generation\n",
    "\n",
    "model.optimizer.lr.assign(0.001) # to reset the learning rate if running additional training\n",
    "\n",
    "# train for 60 epochs\n",
    "for epoch in range (1, 60):\n",
    "    print ('epoch', epoch)\n",
    "\n",
    "    # fit the model for one iteration\n",
    "    model.fit (train_x, train_y,\n",
    "               batch_size=1024, epochs=1,\n",
    "               validation_data=(dev_x, dev_y), #initial_epoch=epoch,\n",
    "               verbose=1)\n",
    "\n",
    "    # select a text seed at random\n",
    "    seed_tweet = tweets.iloc[random.randint(0, len(tweets))]\n",
    "    generated_text = seed_tweet['text'][0:n_seed_chars]\n",
    "    print ('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    # try a range of sampling temperatures\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print ('--------- temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        for i in range (MAX_TWEET_LENGTH - n_seed_chars):\n",
    "            # one-hot encode the characters generated so far\n",
    "            sampled = np.zeros((1, WINDOW_SIZE, len(chars_univ)))\n",
    "            for t, char in enumerate (generated_text):\n",
    "                sampled[0, t, chars_univ_idx[char]] = 1\n",
    "\n",
    "            # sample the next character\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars_univ[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "\n",
    "        print (\"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "char_univ_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning env Python 3.6",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "emoji_text_gen_LSTM.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
