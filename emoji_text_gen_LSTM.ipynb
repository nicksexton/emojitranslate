{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Notebook that trains an LSTM to generate tweets based on a given emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "First we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nickdbn/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_load_utils as util\n",
    "\n",
    "from importlib import reload\n",
    "util = reload (util)\n",
    "\n",
    "\n",
    "tweets = util.filter_tweets_min_count(\n",
    "    util.read_tweet_data('data/emojis_homemade.csv'),\n",
    "    min_count=1000)\n",
    "\n",
    "tweets['text'] = util.filter_text_for_handles(tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT [VID] 181023 - Foi adicionada a letra D no ...\n",
       "1    RT 181023 Kris Wu Studio update (3/3)Legendary...\n",
       "2    RT Now you are watching Indian SuperStar with ...\n",
       "3                                      dats for keeps \n",
       "6                               Holy shit no I think. \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.filter_text_for_handles(tweets.iloc[0:5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT [VID] 181023 - Foi adicionada a letra D no ...</td>\n",
       "      <td>©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT 181023 Kris Wu Studio update (3/3)Legendary...</td>\n",
       "      <td>💫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT Now you are watching Indian SuperStar with ...</td>\n",
       "      <td>😎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dats for keeps</td>\n",
       "      <td>💛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Holy shit no I think.</td>\n",
       "      <td>😩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT army, follow who retweet this</td>\n",
       "      <td>👑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT Simply K-Pop harddrive dump# #BerryGood #Me...</td>\n",
       "      <td>🤩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Happy birthday nellie hope you have a fantasti...</td>\n",
       "      <td>❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT \"I have passed through fire\"Thank you for b...</td>\n",
       "      <td>💕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT Incredible to be involved in the making of ...</td>\n",
       "      <td>😱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT Too much feels #BTS #MPN #BTSARMY https://t...</td>\n",
       "      <td>😢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT #PL TOP SCORERS 7 - 6 - the goods  https://...</td>\n",
       "      <td>🔥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[DEPASCAL] RUSSEL HOODIE BLUE https://t.co/CR4...</td>\n",
       "      <td>🔗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The joys of having a make up artist as your be...</td>\n",
       "      <td>😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RT army, follow who retweet this</td>\n",
       "      <td>👑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Someone didnt read the article.</td>\n",
       "      <td>🙄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RT Happy 23rd Birthday to Duckie Thot  https:/...</td>\n",
       "      <td>💕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT follow everyone who retweets this,</td>\n",
       "      <td>💓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT Incredible to be involved in the making of ...</td>\n",
       "      <td>😱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>WOW let me know when I can come play games</td>\n",
       "      <td>🙃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RT  You have all decided to push your way thro...</td>\n",
       "      <td>🤔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Somebody stop simone biles omg</td>\n",
       "      <td>🔥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RT My fetish is to have enough time to do all ...</td>\n",
       "      <td>💦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RT [DEPASCAL] RUSSEL HOODIE BLUE https://t.co/...</td>\n",
       "      <td>🔗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>text</td>\n",
       "      <td>emoji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Frosted Flakes be high as hell you when you good</td>\n",
       "      <td>😭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RT  &amp;amp; RT this contest tweet NOW &amp;amp; we w...</td>\n",
       "      <td>❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>most people need clueS !  Lots of them  !!</td>\n",
       "      <td>😄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RT Big Hit is fast, but ARMYs are faster.  htt...</td>\n",
       "      <td>😁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RT foodtrip with them@itzjncko https://t.co/OA...</td>\n",
       "      <td>💯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728708</th>\n",
       "      <td>RT 16th November London See you soon #TheReign...</td>\n",
       "      <td>🔥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728709</th>\n",
       "      <td>RT Happy birthday Dream Kardashian!  https://t...</td>\n",
       "      <td>💕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728710</th>\n",
       "      <td>RT These two guys should find another place to...</td>\n",
       "      <td>❗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728711</th>\n",
       "      <td>Btw will you join mbbselcaday now?</td>\n",
       "      <td>😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728712</th>\n",
       "      <td>RT jennie cried so hard</td>\n",
       "      <td>😭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728713</th>\n",
       "      <td>RT Hello Counselor filming done!  https://t.co...</td>\n",
       "      <td>💛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728715</th>\n",
       "      <td>RT [IG] 181111  kieltutin updated with BLACKPI...</td>\n",
       "      <td>🔗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728716</th>\n",
       "      <td>Check this out  King of Masked Singer # # (Cr....</td>\n",
       "      <td>👉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728717</th>\n",
       "      <td>Lmao  It means people were drinking heavily</td>\n",
       "      <td>😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728718</th>\n",
       "      <td>if shit goes left later I'm sure u gon be in t...</td>\n",
       "      <td>😆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728719</th>\n",
       "      <td>text</td>\n",
       "      <td>emoji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728721</th>\n",
       "      <td>RT I think we are ALL crying  https://t.co/ZW6...</td>\n",
       "      <td>☹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728722</th>\n",
       "      <td>Finally</td>\n",
       "      <td>💕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728723</th>\n",
       "      <td>Guess who ran away from acads? pakkkk https://...</td>\n",
       "      <td>😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728724</th>\n",
       "      <td>RT Tag someone you miss all day  https://t.co/...</td>\n",
       "      <td>😔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728726</th>\n",
       "      <td>worse than Nigga Moment+ Nigga Synthesis</td>\n",
       "      <td>😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728727</th>\n",
       "      <td>Slumflower is flipping AWESOME #Hero #Heroine ...</td>\n",
       "      <td>❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728728</th>\n",
       "      <td>Well now I'm the one who trying hard.. But you...</td>\n",
       "      <td>😞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728729</th>\n",
       "      <td>RT if kyungsoo doesnt want it, you cant force ...</td>\n",
       "      <td>🤣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728730</th>\n",
       "      <td>SO FUCKING IN LOVE  https://t.co/BK4Y5SmtKk</td>\n",
       "      <td>😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728732</th>\n",
       "      <td>[_dong_ii posted on his story] thank you so mu...</td>\n",
       "      <td>❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728734</th>\n",
       "      <td>RT Guys this isnt anything to do with #EricaFe...</td>\n",
       "      <td>🚨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728735</th>\n",
       "      <td>RT THE SURPRISE K.O. AT THE BUZZER  https://t....</td>\n",
       "      <td>😱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728736</th>\n",
       "      <td>RT Happy Birthday!!!@Bluecat111177 Love you . ...</td>\n",
       "      <td>😘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728738</th>\n",
       "      <td>RT JISOO WENT TO JENNIE TO COMFORT HER from do...</td>\n",
       "      <td>😭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728740</th>\n",
       "      <td>RT Yall annoying</td>\n",
       "      <td>🙄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728741</th>\n",
       "      <td>RT I am  sure that using brain and internet is...</td>\n",
       "      <td>💯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728742</th>\n",
       "      <td>Susanna stick up for yourself.</td>\n",
       "      <td>👊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728744</th>\n",
       "      <td>Sometimes i wish theres someone to shout at me...</td>\n",
       "      <td>🙄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728746</th>\n",
       "      <td>RT Win, Lose or Tie, Bayern Munchen Till We Di...</td>\n",
       "      <td>❤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460771 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  emoji\n",
       "0       RT [VID] 181023 - Foi adicionada a letra D no ...      ©\n",
       "1       RT 181023 Kris Wu Studio update (3/3)Legendary...      💫\n",
       "2       RT Now you are watching Indian SuperStar with ...      😎\n",
       "3                                         dats for keeps       💛\n",
       "6                                  Holy shit no I think.       😩\n",
       "7                       RT army, follow who retweet this       👑\n",
       "8       RT Simply K-Pop harddrive dump# #BerryGood #Me...      🤩\n",
       "9       Happy birthday nellie hope you have a fantasti...      ❤\n",
       "10      RT \"I have passed through fire\"Thank you for b...      💕\n",
       "12      RT Incredible to be involved in the making of ...      😱\n",
       "13      RT Too much feels #BTS #MPN #BTSARMY https://t...      😢\n",
       "14      RT #PL TOP SCORERS 7 - 6 - the goods  https://...      🔥\n",
       "15      [DEPASCAL] RUSSEL HOODIE BLUE https://t.co/CR4...      🔗\n",
       "16      The joys of having a make up artist as your be...      😂\n",
       "18                      RT army, follow who retweet this       👑\n",
       "19                       Someone didnt read the article.       🙄\n",
       "20      RT Happy 23rd Birthday to Duckie Thot  https:/...      💕\n",
       "21                 RT follow everyone who retweets this,       💓\n",
       "22      RT Incredible to be involved in the making of ...      😱\n",
       "24            WOW let me know when I can come play games       🙃\n",
       "27      RT  You have all decided to push your way thro...      🤔\n",
       "28                        Somebody stop simone biles omg       🔥\n",
       "30      RT My fetish is to have enough time to do all ...      💦\n",
       "32      RT [DEPASCAL] RUSSEL HOODIE BLUE https://t.co/...      🔗\n",
       "33                                                   text  emoji\n",
       "34      Frosted Flakes be high as hell you when you good       😭\n",
       "36      RT  &amp; RT this contest tweet NOW &amp; we w...      ❤\n",
       "37          most people need clueS !  Lots of them  !!         😄\n",
       "38      RT Big Hit is fast, but ARMYs are faster.  htt...      😁\n",
       "39      RT foodtrip with them@itzjncko https://t.co/OA...      💯\n",
       "...                                                   ...    ...\n",
       "728708  RT 16th November London See you soon #TheReign...      🔥\n",
       "728709  RT Happy birthday Dream Kardashian!  https://t...      💕\n",
       "728710  RT These two guys should find another place to...      ❗\n",
       "728711                 Btw will you join mbbselcaday now?      😂\n",
       "728712                           RT jennie cried so hard       😭\n",
       "728713  RT Hello Counselor filming done!  https://t.co...      💛\n",
       "728715  RT [IG] 181111  kieltutin updated with BLACKPI...      🔗\n",
       "728716  Check this out  King of Masked Singer # # (Cr....      👉\n",
       "728717        Lmao  It means people were drinking heavily      😂\n",
       "728718  if shit goes left later I'm sure u gon be in t...      😆\n",
       "728719                                               text  emoji\n",
       "728721  RT I think we are ALL crying  https://t.co/ZW6...      ☹\n",
       "728722                                            Finally      💕\n",
       "728723  Guess who ran away from acads? pakkkk https://...      😂\n",
       "728724  RT Tag someone you miss all day  https://t.co/...      😔\n",
       "728726           worse than Nigga Moment+ Nigga Synthesis      😂\n",
       "728727  Slumflower is flipping AWESOME #Hero #Heroine ...      ❤\n",
       "728728  Well now I'm the one who trying hard.. But you...      😞\n",
       "728729  RT if kyungsoo doesnt want it, you cant force ...      🤣\n",
       "728730        SO FUCKING IN LOVE  https://t.co/BK4Y5SmtKk      😍\n",
       "728732  [_dong_ii posted on his story] thank you so mu...      ❤\n",
       "728734  RT Guys this isnt anything to do with #EricaFe...      🚨\n",
       "728735  RT THE SURPRISE K.O. AT THE BUZZER  https://t....      😱\n",
       "728736  RT Happy Birthday!!!@Bluecat111177 Love you . ...      😘\n",
       "728738  RT JISOO WENT TO JENNIE TO COMFORT HER from do...      😭\n",
       "728740                                  RT Yall annoying       🙄\n",
       "728741  RT I am  sure that using brain and internet is...      💯\n",
       "728742                    Susanna stick up for yourself.       👊\n",
       "728744  Sometimes i wish theres someone to shout at me...      🙄\n",
       "728746  RT Win, Lose or Tie, Bayern Munchen Till We Di...      ❤\n",
       "\n",
       "[460771 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     RT [VID] 181023 - Foi adicionada a letra D no ...\n",
       "emoji                                                    ©\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     RT 181023 Kris Wu Studio update (3/3)Legendary...\n",
       "emoji                                                    💫\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460771, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "MAX_TWEET_LENGTH = 160\n",
    "WINDOW_SIZE = 40\n",
    "STEP = 3\n",
    "\n",
    "chars_univ, chars_univ_idx = util.get_universal_chars_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tweets_train = tweets.iloc[0:3000] # 100 just to test the model works\n",
    "tweets_dev = tweets.iloc[3000:3200] # 100 just to test the model works\n",
    "# tweets_test = tweets.iloc[2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 4.318266868591309 s\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "\n",
    "train_x, train_y = util.convert_tweet_to_xy(tweets_train)\n",
    "dev_x, dev_y = util.convert_tweet_to_xy(tweets_train)\n",
    "\n",
    "print (\"completed in\", time.time()-tic, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 40, 93)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        : \n",
      "                                        : \n",
      "                                      RT: \n",
      "                                   RT [V:I\n",
      "                                RT [VID]: \n",
      "                             RT [VID] 18:1\n",
      "                          RT [VID] 18102:3\n",
      "                       RT [VID] 181023 -: \n",
      "                    RT [VID] 181023 - Fo:i\n",
      "                 RT [VID] 181023 - Foi a:d\n",
      "              RT [VID] 181023 - Foi adic:i\n",
      "           RT [VID] 181023 - Foi adicion:a\n",
      "        RT [VID] 181023 - Foi adicionada: \n",
      "     RT [VID] 181023 - Foi adicionada a :l\n",
      "  RT [VID] 181023 - Foi adicionada a let:r\n",
      "T [VID] 181023 - Foi adicionada a letra :D\n",
      "VID] 181023 - Foi adicionada a letra D n:o\n",
      "] 181023 - Foi adicionada a letra D no o:u\n",
      "81023 - Foi adicionada a letra D no outd:o\n",
      "23 - Foi adicionada a letra D no outdoor: \n",
      "- Foi adicionada a letra D no outdoor mi:s\n",
      "oi adicionada a letra D no outdoor miste:r\n",
      "adicionada a letra D no outdoor misterio:s\n",
      "cionada a letra D no outdoor misterioso :d\n",
      "nada a letra D no outdoor misterioso do :#\n",
      "a a letra D no outdoor misterioso do #BT:S\n",
      " letra D no outdoor misterioso do #BTS e:m\n",
      "tra D no outdoor misterioso do #BTS em H:o\n",
      " D no outdoor misterioso do #BTS em Holl:y\n",
      "no outdoor misterioso do #BTS em Hollywo:o\n",
      "outdoor misterioso do #BTS em Hollywood.:F\n",
      "door misterioso do #BTS em Hollywood.For:m\n",
      "r misterioso do #BTS em Hollywood.Forman:d\n",
      "isterioso do #BTS em Hollywood.Formando:: \n",
      "erioso do #BTS em Hollywood.Formando: BT:S\n",
      "oso do #BTS em Hollywood.Formando: BTS A:N\n",
      " do #BTS em Hollywood.Formando: BTS AND.:.\n",
      " #BTS em Hollywood.Formando: BTS AND... : \n",
      "TS em Hollywood.Formando: BTS AND...  IL:O\n",
      "em Hollywood.Formando: BTS AND...  ILOVE:P\n",
      "                                        : \n",
      "                                        : \n",
      "                                        : \n",
      "                                        : \n",
      "                                        :R\n",
      "                                     RT :1\n",
      "                                  RT 181:0\n",
      "                               RT 181023: \n",
      "                            RT 181023 Kr:i\n",
      "                         RT 181023 Kris :W\n"
     ]
    }
   ],
   "source": [
    "for i in range (50):\n",
    "    print (util.x_y_bool_array_to_sentence(train_x, train_y, chars_univ, position=i, separator=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Building a network\n",
    "Intially, let's try generating tweets by training a network on just the tweet data. Once we have an idea how well we can get a network to generate tweets (remember, character by character), we'll compare it to a network that learns to generate tweets by predicting the next chracter jointly from the preceding text and an overall emoji. (remember, this dataset is tweets that all contain exactly one emoji)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Simple network - a single LSTM into a Dense softmax classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(WINDOW_SIZE, len(chars_univ))))\n",
    "model.add(layers.Dense(len(chars_univ), activation='softmax'))\n",
    "\n",
    "# loss function - targets are one-hot encoded\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Training the model and sampling from it using a standard character-by-character method\n",
    "1. Draw a probability distribution for the next character\n",
    "2. Reweight the distribution using a temperature parameter\n",
    "3. Sample the next character at random using the reweighted distribution\n",
    "4. Add the new character at the end of the available list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def sample (preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## train the model, generate text\n",
    "Use a range of temeratures after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT [VID] 1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[0]['text'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 177s 1ms/step - loss: 2.1425 - val_loss: 1.9504\n",
      "--- Generating with seed: \"RT So exci\"\n",
      "--------- temperature: 0.2\n",
      "RT So exci  too  oo   o    t t      o                            o  e     oe  oo  to os               o        o  o   to o teo  t   e    tao  o      o    t   t \n",
      "\n",
      "--------- temperature: 0.5\n",
      "    t   t :oooy te  l t tt  s    tud :hnw  g u  sr otts   oieo ethee  oo o au   eooatt  e rptog ooBt    lra  h   ehto eh taodoiioylptit roeskltRm  a rnoleotfem \n",
      "\n",
      "--------- temperature: 1.0\n",
      "noleotfem a: w. tioneinhileew3ktey eisnyE yein Viwr*f.u:% o:l.aQdGZ vNp1teMKrIoesP  gt!sozyceetuon3fRetoJ0di9skRnqwSoIi kvgr9gloosac Foo VbfbS9hay:RfWeth G:ooo \n",
      "\n",
      "--------- temperature: 1.2\n",
      "eth G:ooo rtQBiB XtMHeix]i5cqkB#I]1iKaXy7~HlxMdaweifS:gslgat epU MnVke0yNct! at6sJK:qO6FKM#@X,y347Ohvthvs:snuah&ur/ef7S kTiJBxIc14 ep8g8uooi t?;icurettllal0sh U\n",
      "\n",
      "epoch 2\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 176s 1ms/step - loss: 1.8339 - val_loss: 1.7439\n",
      "--- Generating with seed: \"RT i look \"\n",
      "--------- temperature: 0.2\n",
      "RT i look              t                a                                  m                   t      i   t                               s                     \n",
      "\n",
      "--------- temperature: 0.5\n",
      "          a   e  ea   s h   ei s  tt   eta mh  l   yt  y t   nha  e eT         gee s      Lei     o  u   e  up  en     oe  e m  o    e aeoue o   oas iake    t  \n",
      "\n",
      "--------- temperature: 1.0\n",
      "ake    t  @atstiByin  ojaItt pMsa!minps# lgoTGc r umc FI NjaukTl  vjgmaT wd ptatmR;ukeon  e RX. ye pcuutirdtta rdt nvsu  loe  c teacmgGkbhe beoe   0c t/nrE   R:\n",
      "\n",
      "--------- temperature: 1.2\n",
      "t/nrE   R:@ioPedYiAfoh\"DtiJMufPgI#INo W trv ?yefcegt   :lhlvuIi 5 a s dswx ncmAc eoa5icw oi EiSEWohhne4d Iaa:uZs-!bE83  I:b viliiItii!dswoffeoln Ta.io  xlg0. g,\n",
      "\n",
      "epoch 3\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 174s 1ms/step - loss: 1.7012 - val_loss: 1.6686\n",
      "--- Generating with seed: \"RT I cast \"\n",
      "--------- temperature: 0.2\n",
      "RT I cast                                                                                                                                                       \n",
      "\n",
      "--------- temperature: 0.5\n",
      "                                                                                                                                                                \n",
      "\n",
      "--------- temperature: 1.0\n",
      "                        n        e          R  Smeg r                   N      mk h  o        IYRe   u       Ieo     e £      eT      Rw         i  IpJ       Ru\n",
      "\n",
      "--------- temperature: 1.2\n",
      "J       Ru YL  RO ' b  T Ree i e vr sgYm  aO Tpa     #i  R   Hv  O    eR    I u    a    v  ul'          RRTO  al  s  r  2   c# o Bl yd         r      T S aeTIes\n",
      "\n",
      "epoch 4\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 175s 1ms/step - loss: 1.5907 - val_loss: 1.5466\n",
      "--- Generating with seed: \"RT this we\"\n",
      "--------- temperature: 0.2\n",
      "RT this wetti t att  t t    tt  toatt    ttaet e tttt  tt  t tt t tt tt t t  tt  tttt ttt   a t    t    t t t et tt      t   tt   tt  e tt   t tt o tt t   it et\n",
      "\n",
      "--------- temperature: 0.5\n",
      " t   it ett tta  t e iawot  e a taee t ie teeett atttttsiet tto  Sii ort  aa teo istt  etdoatieaett tett Cttia     i e teeor  toi ttf  titoateo iihtietotaee    \n",
      "\n",
      "--------- temperature: 1.0\n",
      "totaee    Kxm!a  uoP.Wd iUar t imi eto.-meePee t ec iadVittgatoSGimJim.e te!idS aaLav atfaaat#titgT  #tuiuwE .i4oa rittay t#at :oooitOStarnhimoSaXi9eeuCai Agtua\n",
      "\n",
      "--------- temperature: 1.2\n",
      "uCai AgtuaOodl Tnt IrvM upe  T2ibrii ciRv cc yW  1 g-o-eaF)bc\"1aewemtoor.e[yMITfRuwt'utaatoh Tcta# lo rhme?vabHTtci#  -yk6t6s .hruBn1.FemLtGKtQ a irapptetwmvS#i\n",
      "\n",
      "epoch 5\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 197s 2ms/step - loss: 1.5000 - val_loss: 1.4693\n",
      "--- Generating with seed: \"takes an a\"\n",
      "--------- temperature: 0.2\n",
      "takes an aa  t  a a    a t   i  a         h       t a t at aa a  i a              a  aa        i               t   i       i i    a     ii             oaaa     \n",
      "\n",
      "--------- temperature: 0.5\n",
      " oaaa      eaiia .iiay l t i a a aaoa y   ei o r#ooR i&.7e'  i if tit i  aaiyi ia o  itta.  aw a      a tto i#i ta w ohie rl ya eoaa I  ahcaaaiiaidaai  Adaoau a\n",
      "\n",
      "--------- temperature: 1.0\n",
      "  Adaoau a2 eetb uNyytcdswenTotjK#.lcoaVi.i titr1rwii ieanipaotpvr g(A  Lado #ro\"is  a eiA0Intlbwbi!riAoodta#aYliheIb lTi2u iCntGGusseeeOtrNaiitShtscoa5t o Pauu\n",
      "\n",
      "--------- temperature: 1.2\n",
      "a5t o PauulanVaaohyiukono #fsvrttKhSroIyRaaelesly lLktHclnh ictpdXtdtit2pt iD f8u  oY#KtrNo WJoBDT2  tea aiF1ihed  wuCnaulstaGakhiairplS io &h M y/u#sDmrr'oeflz\n",
      "\n",
      "epoch 6\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 176s 1ms/step - loss: 1.4341 - val_loss: 1.4158\n",
      "--- Generating with seed: \"RT [ Espec\"\n",
      "--------- temperature: 0.2\n",
      "RT [ Espec      iti    a          ai         e  e ae    a      e  e    n   ae n              e      e a e    e    a e  n          a    i     e    ai         s  \n",
      "\n",
      "--------- temperature: 0.5\n",
      "       s   e  nerndorsaiadae  shy     aa l aah at ass asv i ei eo! ohhioa apotslasniio adeiohdaol d  eteo  f eus e e ntii  atlaie   ri areyrae    f iae  ulo ee \n",
      "\n",
      "--------- temperature: 1.0\n",
      "e  ulo ee ifuoen nk K teudybtt GffahnteH  b fnyfttalntasypamhIeIjerEt paiai hs ln iewnm ePfalSPvirpnEus  2luiel tMmaB ia Oymovsf ahCdu nnaektt dHsnhe ie@   ohtg\n",
      "\n",
      "--------- temperature: 1.2\n",
      "ie@   ohtgasamn#hgGt/i agc1ydrthaZ CetohioadyevbeogCw peMowa evtiDeF i3cashofihntsitNins es0  dt meNTaoeneciKy  nrMu  Scdciey dynPtiSroinA pJ3ihut uhN dnvt+n I8\n",
      "\n",
      "epoch 7\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 173s 1ms/step - loss: 1.3930 - val_loss: 1.3791\n",
      "--- Generating with seed: \"Can we ple\"\n",
      "--------- temperature: 0.2\n",
      "Can we ple       t t         t         t          a      t        i t a                t                       t                         t        i   t         \n",
      "\n",
      "--------- temperature: 0.5\n",
      "t         i ir   it  lmtri att o   ua w iu i i taaat r  t c ithoisupm e _osit  atiitoi ut ti raais   ettn sltNs         ti t issT  lt Paii   mto st  restai  i r\n",
      "\n",
      "--------- temperature: 1.0\n",
      "estai  i rpo tei sdha i hla aEl Wrth(,0mnqhr  uCu otaNtitgit A itiat a oeaiat.V  svew iiOrv- pt!!lshsurr wNntamLSt  ssF iTJ wighrdinO1 eoSMuiaacarriw   h dVosGI\n",
      "\n",
      "--------- temperature: 1.2\n",
      "  h dVosGIDf3oh d  nglfhBYuWetr ltuFiiiw)a9rsE !uo7RitgtjGDgls sidoHeynafetCYc#.tae ytskdktdi  yWistuhmti vtrcvyuOd] mrat0ewi srll!otsopP2cDtsVtlKWTi   ln,   na\n",
      "\n",
      "epoch 8\n",
      "Train on 120000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " 94208/120000 [======================>.......] - ETA: 27s - loss: 1.3644"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "n_seed_chars = 10 # number of characters to use as a seed for text generation\n",
    "\n",
    "model.optimizer.lr.assign(0.001) # to reset the learning rate if running additional training\n",
    "\n",
    "# train for 60 epochs\n",
    "for epoch in range (1, 60):\n",
    "    print ('epoch', epoch)\n",
    "\n",
    "    # fit the model for one iteration\n",
    "    model.fit (train_x, train_y,\n",
    "               batch_size=1024, epochs=1,\n",
    "               validation_data=(dev_x, dev_y), #initial_epoch=epoch,\n",
    "               verbose=1)\n",
    "\n",
    "    # select a text seed at random\n",
    "    seed_tweet = tweets.iloc[random.randint(0, len(tweets))]\n",
    "    generated_text = seed_tweet['text'][0:n_seed_chars]\n",
    "    print ('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    # try a range of sampling temperatures\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print ('--------- temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        for i in range (MAX_TWEET_LENGTH - n_seed_chars):\n",
    "            # one-hot encode the characters generated so far\n",
    "            sampled = np.zeros((1, WINDOW_SIZE, len(chars_univ)))\n",
    "            for t, char in enumerate (generated_text):\n",
    "                sampled[0, t, chars_univ_idx[char]] = 1\n",
    "\n",
    "            # sample the next character\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars_univ[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "\n",
    "        print (\"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char_univ_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-b600fd042a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchar_univ_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'char_univ_idx' is not defined"
     ]
    }
   ],
   "source": [
    "char_univ_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "emoji_text_gen_LSTM.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
